# OpenClaw + QMD 学习卡（2026-02-10）

## 1. 文章核心结论（已吸收）

- 长会话性能瓶颈的本质是“上下文爆炸”：把整份长期记忆直接塞进模型输入，导致慢、贵、易崩。
- QMD 思路是“检索后再注入”：先本地语义检索相关片段，再将少量高相关内容喂给模型。
- 预期收益方向：
  - token 显著下降
  - 响应速度显著提升
  - API 成本显著降低
  - 长会话稳定性提升

## 2. 对 Yoyoo 的价值

- 非常契合我们“AI CEO + 长期运营”的场景：
  - CEO 要长期记忆
  - 执行层（Claw/Nano）会产生大量历史
  - 如果不做检索压缩，越用越慢、越贵
- 这类能力应放在“Yoyoo Brain 记忆层策略”中，而不是只依赖某个单一执行器。

## 3. 我们的落地原则

- 先验证，再全量切换：
  - 不直接相信单篇文章数据
  - 用我们自己的任务集做 A/B 对照
- 指标优先：
  - p50/p95 响应时延
  - 单请求 token
  - 单任务成本
  - 失败率/超时率
- 可回滚：
  - 任意时候可回退到 sqlite/default memory backend

## 4. Yoyoo 场景下的执行计划（P0）

1. 建立基线：记录当前 20 个典型任务的时延、token、成本、成功率。
2. 在服务器 OpenClaw 启用 QMD（灰度，不全量）。
3. 运行同一批回放任务，收集同口径指标。
4. 形成对比报告：收益、风险、回滚条件。
5. 达标后推广到生产；不达标则回退并保留结论。

## 5. 达标门槛（建议）

- p50 时延下降 >= 40%
- 平均 token 下降 >= 60%
- 失败率不升高（最好下降）
- 7 天内无新增 P0/P1 稳定性事故

## 6. 风险提醒

- QMD 依赖本地模型与索引，首次构建耗时和资源占用要预估。
- 不同版本 OpenClaw 的配置键可能变化，必须按当前版本文档核对。
- 指标收益会受任务类型影响，不能只看单个案例。

## 7. 下一步（待你指令）

- 我可以直接做一版《QMD 灰度实验方案 + 自动采样脚本》，用于你现在线上 Claw 的真实数据验证。
