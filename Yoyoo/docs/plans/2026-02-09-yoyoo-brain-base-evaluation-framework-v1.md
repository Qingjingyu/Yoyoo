# Yoyoo 大脑底座综合评测机制 v1

> 日期：2026-02-09  
> 用途：在候选项目之间选“Yoyoo Brain 底座”  
> 候选：Letta / memU / OpenAkita / Nanobot / OpenClaw

## 1. 评分维度（你关心的 11 项）

每项 0-10 分，按权重折算到 100 分：

| 维度 | 权重 | 重点看什么 | 如何验证（必须有证据） |
|---|---:|---|---|
| 记忆能力 | 15 | 长期记忆、跨会话召回、记忆结构 | 连续 3 天多轮任务后召回准确率 |
| 执行能力 | 12 | 任务执行、工具调度、失败重试 | 固定任务集成功率与重试次数 |
| 交互能力 | 8 | 飞书/钉钉/CLI/API 等入口完整性 | 多渠道回包一致性测试 |
| 代码生成 | 10 | 代码产出质量、可运行率 | 10 个编码任务通过率 |
| 自我迭代 | 10 | 反思、策略更新、自修复 | 同类任务二次成功率提升 |
| 兼容能力 | 8 | 模型/系统/工具可替换性 | 更换模型与执行器的改造成本 |
| 稳定性 | 10 | 长时间运行、崩溃恢复、监控 | 24h 压测、自动恢复次数 |
| 学习能力 | 9 | 用户偏好学习、任务经验沉淀 | 人工反馈后策略命中变化 |
| Skill 生态 | 8 | skill 发现/安装/治理能力 | skill 接入耗时与成功率 |
| MCP 能力 | 5 | MCP 标准支持深度 | MCP 工具发现/调用成功率 |
| GitHub 学习 | 5 | 从开源项目吸收能力 | 从 repo 提取并复用能力闭环 |

## 2. 评分方法

1. 每维 0-10 分，必须附证据（日志、命令输出、接口结果）。  
2. 加权总分：`Total = Σ(维度分 × 权重/10)`。  
3. 生产可用门槛：
- 总分 >= 75
- 记忆 >= 7
- 稳定性 >= 7
- 自我迭代 >= 6

## 3. 首轮静态评估（公开资料 + 仓库现状）

> 说明：本轮为“静态评估”，未做完整 24h 动态压测；动态分应在下一轮补齐。  
> 数据参考时间：2026-02-09（GitHub API / README）。

| 项目 | 总分(100) | 结论 | 角色建议 |
|---|---:|---|---|
| Letta | 82 | 最适合做大脑底座 | Brain 主底座（推荐） |
| OpenAkita | 74 | 功能思路强，但成熟度偏早期 | 参考实现，不建议直接做主底座 |
| memU | 71 | 记忆非常强，但不是完整大脑 | 作为记忆子系统接入 |
| OpenClaw | 68 | 执行与渠道极强，非大脑定位 | 主执行层 |
| Nanobot | 64 | 轻量执行优秀，偏执行层 | 备份/并行执行层 |

## 4. 落地建议（针对 Yoyoo）

1. 底座：Letta（大脑）  
2. 记忆增强：memU 思路/组件（按需接入）  
3. 执行层：OpenClaw 主 + Nanobot 备  
4. 治理：所有外部能力先 Adapter 化，再灰度，不直连 Brain 内核

## 5. 下一步动态评测清单（建议 7 天）

1. 连续任务集（30 条）成功率对比  
2. 24h 稳定性压测（崩溃次数、恢复时间）  
3. “继续上次任务”命中率  
4. 人工反馈后策略改进幅度  
5. 执行器切换成本（Claw -> Nano）验证

